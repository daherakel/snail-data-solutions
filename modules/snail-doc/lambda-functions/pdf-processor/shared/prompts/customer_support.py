"""
Customer Support Prompts
Prompts espec√≠ficos para el caso de uso de atenci√≥n al cliente
(Plantilla para futuro uso)
"""

from typing import Any, Dict, List, Optional

from .base_prompts import BasePrompts


class CustomerSupportPrompts(BasePrompts):
    """
    Prompts espec√≠ficos para atenci√≥n al cliente.
    Extiende BasePrompts con funcionalidades espec√≠ficas de soporte.

    NOTA: Este es un template para futuro uso.
    """

    def __init__(
        self,
        personality: str = "warm",
        language: str = "es",
        custom_instructions: str = "",
    ):
        """Inicializa prompts para atenci√≥n al cliente."""
        super().__init__(personality, language, custom_instructions)

    def get_system_prompt(self) -> str:
        """
        Obtiene el prompt del sistema para atenci√≥n al cliente.

        Returns:
            String con el prompt del sistema espec√≠fico para soporte.
        """
        base_prompt = super().get_system_prompt()

        # Agregar instrucciones espec√≠ficas de atenci√≥n al cliente
        support_specific = """

üéß ESPEC√çFICO PARA ATENCI√ìN AL CLIENTE:
‚Ä¢ Debes ser emp√°tico y comprensivo con las consultas de los clientes
‚Ä¢ Proporciona informaci√≥n clara y precisa sobre productos/servicios
‚Ä¢ Si no puedes resolver un problema, orienta sobre c√≥mo obtener ayuda adicional
‚Ä¢ Mant√©n un tono profesional pero cercano
‚Ä¢ Prioriza la satisfacci√≥n del cliente
"""

        return base_prompt + support_specific

    def get_escalation_message(self) -> str:
        """
        Obtiene mensaje cuando se necesita escalar a un humano.

        Returns:
            String con mensaje de escalaci√≥n.
        """
        if self.personality == "warm":
            return "Entiendo tu consulta. Para poder ayudarte mejor, voy a conectarte con un agente humano que podr√° asistirte de manera m√°s detallada."
        else:
            return "Su consulta requiere atenci√≥n de un agente humano. Ser√° conectado en breve."

    def format_user_prompt(
        self,
        query: str,
        context_chunks: List[Dict[str, Any]],
        conversation_history: Optional[List[Dict[str, str]]] = None,
    ) -> str:
        """
        Formatea el prompt del usuario con contexto para atenci√≥n al cliente.

        Args:
            query: Pregunta del usuario/cliente
            context_chunks: Chunks de contexto (puede incluir FAQs, pol√≠ticas, etc.)
            conversation_history: Historial de conversaci√≥n

        Returns:
            String con el prompt formateado.
        """
        # Construir contexto
        context = "\n\n".join(
            [
                f"[Fuente: {chunk['metadata']['source']}]\n{chunk['text']}"
                for chunk in context_chunks
            ]
        )

        # Construir historial
        history_context = ""
        if conversation_history:
            history_context = "Historial de la conversaci√≥n:\n"
            for msg in conversation_history[-20:]:
                role = "Cliente" if msg["role"] == "user" else "Asistente"
                history_context += f"{role}: {msg['content']}\n"
            history_context += "\n"

        # Construir el prompt
        user_prompt = f"""{history_context}
Informaci√≥n disponible:
{context}

Consulta del cliente: {query}

Responde de forma emp√°tica y √∫til bas√°ndote en la informaci√≥n disponible."""

        return user_prompt
