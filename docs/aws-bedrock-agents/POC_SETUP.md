# Configuraci√≥n POC Ultra-Econ√≥mica (<$10/mes)

Gu√≠a para implementar un POC/Playground del m√≥dulo AWS Bedrock Agents manteniendo costos bajo $5-10 USD/mes.

## üéØ Objetivo

Crear un agente de AI funcional para probar capacidades sin gastos significativos. Ideal para:
- Playground personal
- Proof of Concept (POC)
- Validaci√≥n de arquitectura
- Testing de funcionalidad

## üí∞ Costo Total Estimado: **$0.50-3/mes**

| Servicio | Configuraci√≥n | Costo Mensual |
|----------|---------------|---------------|
| Bedrock (Claude Haiku) | 100 queries/mes | $0.50 |
| Vector Store (ChromaDB) | Open source, sin l√≠mites | $0.00 |
| Lambda | Dentro de free tier | $0.00 |
| S3 | Backup ChromaDB (<1GB) | $0.02 |
| Step Functions | Dentro de free tier | $0.00 |
| EventBridge | Dentro de free tier | $0.00 |
| **TOTAL** | | **~$0.52/mes** ‚úÖ |

### Escenario con m√°s uso:
- 500 queries/mes: $2.50
- 50 documentos/mes: +$0.02 (S3)
- **Total: $2.52/mes** ‚úÖ

## ‚öôÔ∏è Stack Recomendado para POC

### 1. Modelo de IA: Claude Haiku

**Por qu√© Haiku:**
- **80% m√°s barato** que Sonnet
- Input: $0.25 por mill√≥n tokens (vs $3.00 Sonnet)
- Output: $1.25 por mill√≥n tokens (vs $15.00 Sonnet)
- Suficientemente capaz para POC y testing

**Ejemplo de costos:**
- Query t√≠pica: 2K input + 500 output tokens
- Costo por query: $0.00088 (~0.09 centavos)
- 100 queries: **$0.088** (~9 centavos)
- 1,000 queries: **$0.88** (~88 centavos)

### 2. Vector Store: ChromaDB (Open Source)

**Por qu√© ChromaDB:**
- **100% GRATIS** - Open source (Apache 2.0)
- **Sin l√≠mites** de vectores
- S√∫per f√°cil de implementar (API simple)
- Corre en Lambda (free tier)
- Persistencia en S3 ($0.02/mes)
- Migraci√≥n f√°cil a ECS/Fargate para producci√≥n

**Alternativas gratuitas:**
- FAISS: M√°s r√°pido, m√°s bajo nivel
- Qdrant local: Para desarrollo en tu laptop
- Ver `docs/aws-bedrock-agents/FREE_VECTOR_DB_OPTIONS.md` para detalles

### 3. Procesamiento: Lambda + PyPDF2

**Sin Textract:**
- Usar librer√≠as Python gratuitas:
  - **PyPDF2** para PDFs digitales
  - **pdfplumber** para PDFs complejos
  - **python-docx** para Word docs
  - **pandas** para CSV/Excel

**Costos Lambda:**
- Free tier: 1M requests/mes + 400K GB-segundos/mes
- Para POC: **$0.00** (dentro de free tier)

### 4. Orquestaci√≥n: Step Functions Express

**Por qu√© Express:**
- $1.00 por mill√≥n de requests (vs $25.00 Standard)
- Free tier: Primeras 4,000 transiciones/mes
- Para POC: **$0.00** (dentro de free tier)

### 5. Storage: S3 Standard con Lifecycle

**Optimizaci√≥n:**
- Free tier: 5GB storage primeros 12 meses
- Lifecycle: Mover a Glacier despu√©s de 30 d√≠as
- Para POC (<1GB data): **$0.00 - $0.10/mes**

## üèóÔ∏è Arquitectura Simplificada POC

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Usuario   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  S3 Bucket (documentos)                 ‚îÇ
‚îÇ  - PDFs digitales √∫nicamente            ‚îÇ
‚îÇ  - No usar Textract (gratis)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ trigger
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Lambda: PDF Processor                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ ChromaDB (in-memory)               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ - Carga desde S3                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ - Procesa + indexa                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ - Guarda a S3                      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  - PyPDF2 (gratis)                       ‚îÇ
‚îÇ  - Bedrock embeddings                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  S3 Bucket (chroma_backup/)             ‚îÇ
‚îÇ  - ChromaDB data comprimida             ‚îÇ
‚îÇ  - $0.02/mes                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚ñ≤
       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Lambda: Query Handler                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ ChromaDB (in-memory)               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - Carga desde S3                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - Busca vectores                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - Retorna top-K                    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  - Llama Bedrock (Haiku)                  ‚îÇ
‚îÇ  - Retorna respuesta                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìù Configuraci√≥n Paso a Paso

### Paso 1: Instalar ChromaDB Localmente (Testing)

```bash
# Instalar para testing local
pip install chromadb

# Crear layer para Lambda
mkdir -p lambda-layers/chromadb/python
pip install chromadb -t lambda-layers/chromadb/python/
cd lambda-layers/chromadb
zip -r chromadb-layer.zip python/

# Subir layer a AWS
aws lambda publish-layer-version \
  --layer-name chromadb-layer \
  --zip-file fileb://chromadb-layer.zip \
  --compatible-runtimes python3.11 \
  --region us-east-1
```

### Paso 2: Configurar Terraform Variables

```hcl
# modules/aws-bedrock-agents/terraform/environments/dev/terraform.tfvars

environment = "dev"
project_name = "snail-poc"

# Usar Haiku en lugar de Sonnet
bedrock_model_id = "anthropic.claude-3-haiku-20240307-v1:0"

# Sin OpenSearch - usar ChromaDB en Lambda
use_opensearch = false
vector_store_type = "chromadb"  # Open source, gratis

# Lambda configuration para ChromaDB
lambda_memory_mb = 512  # ChromaDB en memoria
lambda_timeout_seconds = 60  # Tiempo para cargar/guardar S3
lambda_ephemeral_storage_mb = 1024  # /tmp para ChromaDB data

# S3 para backup de ChromaDB
create_chroma_backup_bucket = true

# Sin Textract
enable_textract = false
```

### Paso 3: Configurar Lambda con ChromaDB

```python
# modules/aws-bedrock-agents/lambda-functions/pdf-processor/handler.py

import os
import boto3
import chromadb
from chromadb.config import Settings
from PyPDF2 import PdfReader
from io import BytesIO
import json
import tarfile

# Clientes AWS
s3 = boto3.client('s3')
bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')

# Bucket para backup de ChromaDB
CHROMA_BACKUP_BUCKET = os.environ.get('CHROMA_BACKUP_BUCKET', 'snail-chroma-backup')
CHROMA_BACKUP_KEY = 'chroma_data.tar.gz'

def lambda_handler(event, context):
    # 1. Cargar ChromaDB existente desde S3 (si existe)
    chroma_client = load_chroma_from_s3()

    # 2. Obtener o crear colecci√≥n
    collection = chroma_client.get_or_create_collection(
        name="documents",
        metadata={"hnsw:space": "cosine"}
    )

    # 3. Leer PDF desde S3
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = event['Records'][0]['s3']['object']['key']

    obj = s3.get_object(Bucket=bucket, Key=key)
    pdf = PdfReader(BytesIO(obj['Body'].read()))

    # 4. Extraer texto (GRATIS - PyPDF2)
    text = ""
    for page in pdf.pages:
        text += page.extract_text()

    # 5. Chunking simple
    chunks = simple_chunk(text, chunk_size=500)

    # 6. Generar embeddings y agregar a ChromaDB
    for i, chunk in enumerate(chunks):
        # Generar embedding con Bedrock
        response = bedrock.invoke_model(
            modelId='amazon.titan-embed-text-v1',
            body=json.dumps({"inputText": chunk})
        )
        embedding = json.loads(response['body'].read())['embedding']

        # Agregar a ChromaDB
        collection.add(
            embeddings=[embedding],
            documents=[chunk],
            metadatas=[{"source": key, "chunk_id": i}],
            ids=[f"{key}_{i}"]
        )

    # 7. Persistir ChromaDB a S3
    persist_chroma_to_s3(chroma_client)

    return {
        'statusCode': 200,
        'body': json.dumps({
            'message': 'Document processed',
            'source': key,
            'chunks': len(chunks)
        })
    }

def load_chroma_from_s3():
    """Carga ChromaDB desde S3 o crea nuevo"""
    try:
        # Descargar backup
        s3.download_file(
            CHROMA_BACKUP_BUCKET,
            CHROMA_BACKUP_KEY,
            '/tmp/chroma_data.tar.gz'
        )

        # Extraer
        with tarfile.open('/tmp/chroma_data.tar.gz', 'r:gz') as tar:
            tar.extractall('/tmp/')

        print("ChromaDB loaded from S3")
    except Exception as e:
        print(f"No existing ChromaDB found: {e}")

    # Inicializar cliente
    return chromadb.Client(Settings(
        chroma_db_impl="duckdb+parquet",
        persist_directory="/tmp/chroma"
    ))

def persist_chroma_to_s3(chroma_client):
    """Guarda ChromaDB a S3"""
    # Persistir localmente
    chroma_client.persist()

    # Comprimir
    with tarfile.open('/tmp/chroma_data.tar.gz', 'w:gz') as tar:
        tar.add('/tmp/chroma', arcname='chroma')

    # Subir a S3
    s3.upload_file(
        '/tmp/chroma_data.tar.gz',
        CHROMA_BACKUP_BUCKET,
        CHROMA_BACKUP_KEY
    )

    print("ChromaDB persisted to S3")

def simple_chunk(text, chunk_size=500):
    """Chunking simple sin dependencias externas"""
    words = text.split()
    chunks = []
    current_chunk = []
    current_length = 0

    for word in words:
        current_chunk.append(word)
        current_length += len(word) + 1

        if current_length >= chunk_size:
            chunks.append(' '.join(current_chunk))
            current_chunk = []
            current_length = 0

    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

### Paso 4: Lambda para Queries

```python
# modules/aws-bedrock-agents/lambda-functions/query-handler/handler.py

import os
import boto3
import chromadb
from chromadb.config import Settings
import json
import tarfile

# Clientes AWS
s3 = boto3.client('s3')
bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')

CHROMA_BACKUP_BUCKET = os.environ.get('CHROMA_BACKUP_BUCKET', 'snail-chroma-backup')
CHROMA_BACKUP_KEY = 'chroma_data.tar.gz'

def lambda_handler(event, context):
    query = event.get('query')

    if not query:
        return {
            'statusCode': 400,
            'body': json.dumps({'error': 'Query parameter required'})
        }

    # 1. Cargar ChromaDB desde S3
    chroma_client = load_chroma_from_s3()
    collection = chroma_client.get_collection(name="documents")

    # 2. Generar embedding de la query
    response = bedrock.invoke_model(
        modelId='amazon.titan-embed-text-v1',
        body=json.dumps({"inputText": query})
    )
    query_embedding = json.loads(response['body'].read())['embedding']

    # 3. Buscar en ChromaDB (GRATIS)
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=5,
        include=['documents', 'metadatas', 'distances']
    )

    # 4. Construir contexto
    if not results['documents'][0]:
        return {
            'statusCode': 404,
            'body': json.dumps({'error': 'No documents found in database'})
        }

    context = "\n\n".join(results['documents'][0])

    # 5. Llamar a Claude Haiku (BARATO)
    prompt = f"""Contexto de documentos:

{context}

Pregunta del usuario: {query}

Por favor, responde la pregunta bas√°ndote √∫nicamente en el contexto proporcionado. Si la informaci√≥n no est√° en el contexto, ind√≠calo claramente."""

    response = bedrock.invoke_model(
        modelId='anthropic.claude-3-haiku-20240307-v1:0',
        body=json.dumps({
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 500,
            "messages": [{"role": "user", "content": prompt}]
        })
    )

    answer = json.loads(response['body'].read())['content'][0]['text']

    return {
        'statusCode': 200,
        'body': json.dumps({
            'answer': answer,
            'sources': [m['source'] for m in results['metadatas'][0]],
            'confidence_scores': results['distances'][0]
        })
    }

def load_chroma_from_s3():
    """Carga ChromaDB desde S3"""
    # Descargar
    s3.download_file(
        CHROMA_BACKUP_BUCKET,
        CHROMA_BACKUP_KEY,
        '/tmp/chroma_data.tar.gz'
    )

    # Extraer
    with tarfile.open('/tmp/chroma_data.tar.gz', 'r:gz') as tar:
        tar.extractall('/tmp/')

    # Inicializar cliente
    return chromadb.Client(Settings(
        chroma_db_impl="duckdb+parquet",
        persist_directory="/tmp/chroma"
    ))
```

## üö´ Qu√© NO Hacer en POC

Para mantener costos bajos:

‚ùå **NO usar OpenSearch Serverless** ($175/mes m√≠nimo)
‚úÖ Usar Pinecone free tier o FAISS

‚ùå **NO usar Claude Sonnet/Opus** para testing
‚úÖ Usar Claude Haiku (80% m√°s barato)

‚ùå **NO usar Textract** para PDFs digitales
‚úÖ Usar PyPDF2/pdfplumber (gratis)

‚ùå **NO procesar im√°genes/PDFs escaneados** en POC
‚úÖ Solo PDFs digitales inicialmente

‚ùå **NO dejar Step Functions en Standard**
‚úÖ Usar Express workflows

‚ùå **NO mantener documentos en S3 Standard indefinidamente**
‚úÖ Lifecycle a Glacier despu√©s de 7-30 d√≠as

## üìä Monitoreo de Costos

### Configurar Alertas

```bash
# AWS Budget para alertas
aws budgets create-budget \
  --account-id $(aws sts get-caller-identity --query Account --output text) \
  --budget file://budget.json

# budget.json
{
  "BudgetName": "snail-poc-monthly-budget",
  "BudgetLimit": {
    "Amount": "10",
    "Unit": "USD"
  },
  "TimeUnit": "MONTHLY",
  "BudgetType": "COST"
}
```

### Tags para Tracking

Todos los recursos deben tener:
```hcl
tags = {
  Project     = "snail-poc"
  Environment = "dev"
  CostCenter  = "playground"
  Owner       = "tu-nombre"
}
```

## üéì Limitaciones del POC

**Documenta claramente que este POC NO es para producci√≥n:**

1. **Escalabilidad limitada**: Pinecone free tier ‚Üí m√°ximo ~5K docs
2. **Performance**: Haiku es m√°s r√°pido pero menos preciso que Sonnet
3. **Sin OCR**: Solo PDFs digitales (no im√°genes/escaneados)
4. **Sin alta disponibilidad**: Configuraci√≥n m√≠nima
5. **Sin monitoring avanzado**: Solo CloudWatch b√°sico

## üöÄ Migraci√≥n a Producci√≥n

Cuando el POC valide la soluci√≥n, migrar a:

**Modelo**: Haiku ‚Üí Sonnet 4.5
**Vector Store**: Pinecone free ‚Üí Aurora pgvector ($50-80/mes) o OpenSearch ($175+/mes)
**OCR**: Agregar Textract para documentos escaneados
**Monitoring**: CloudWatch dashboards + alertas
**Ambientes**: dev + staging + prod separados

**Costo producci√≥n**: $120-450/mes (seg√∫n volumen)

## üìù Checklist de Setup

- [ ] Instalar ChromaDB localmente para testing
- [ ] Crear Lambda layer con ChromaDB
- [ ] Crear bucket S3 para backup de ChromaDB
- [ ] Modificar terraform.tfvars para usar Haiku + ChromaDB
- [ ] Implementar Lambdas con ChromaDB + PyPDF2
- [ ] Configurar Lambda con 512MB RAM y 60s timeout
- [ ] Configurar S3 lifecycle policies para backups
- [ ] Crear AWS Budget de $5/mes con alertas
- [ ] Usar Step Functions Express (no Standard)
- [ ] Documentar limitaciones del POC
- [ ] Testear con 5-10 documentos inicialmente
- [ ] Verificar costos en AWS Cost Explorer despu√©s de 1 semana

## üí° Tips para Minimizar Costos A√∫n M√°s

1. **Cachear resultados**: No re-procesar documentos
2. **Batch processing**: Procesar m√∫ltiples docs juntos
3. **Prompt caching**: Reusar prompts comunes (90% ahorro)
4. **Lazy indexing**: Solo indexar cuando sea necesario
5. **Limitar tama√±o de chunks**: Menos tokens = menos costo
6. **Usar S3 Intelligent Tiering**: Auto-optimiza costos
7. **Apagar recursos cuando no se usen**: Lambdas solo ejecutan cuando se invocan

## ‚ö†Ô∏è IMPORTANTE

Este setup est√° optimizado para **PLAYGROUND/POC √∫nicamente**.

Para uso en producci√≥n o con clientes, consultar `COST_ANALYSIS.md` para configuraciones apropiadas.

---

**Con esta configuraci√≥n, puedes tener un agente AI funcional por menos de $3/mes.** üéâ

## üìö Recursos Adicionales

- **Opciones Gratuitas Detalladas**: `docs/aws-bedrock-agents/FREE_VECTOR_DB_OPTIONS.md`
- **Comparativa Vector DBs**: `docs/aws-bedrock-agents/VECTOR_DB_COMPARISON.md`
- **An√°lisis Completo de Costos**: `docs/aws-bedrock-agents/COST_ANALYSIS.md`
- **ChromaDB Docs**: https://docs.trychroma.com/
- **AWS Bedrock Pricing**: https://aws.amazon.com/bedrock/pricing/
